{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e9879f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26e0eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b7838e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\FPGA\\GUSN\\.venv\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "f:\\FPGA\\GUSN\\.venv\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:465: UserWarning: Warning: Enabling `experimental_preserve_all_tensors` with the BUILTIN or AUTO op resolver is intended for debugging purposes only. Be aware that this can significantly increase memory usage by storing all intermediate tensors. If you encounter memory problems or are not actively debugging, consider disabling this option.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"model_notnorm_nosoft\", experimental_preserve_all_tensors=True)\n",
    "interpreter.allocate_tensors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7671da96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'serving_default_flatten_input:0',\n",
       " 'index': 0,\n",
       " 'shape': array([ 1, 28, 28]),\n",
       " 'shape_signature': array([-1, 28, 28]),\n",
       " 'dtype': numpy.float32,\n",
       " 'quantization': (0.0, 0),\n",
       " 'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "  'zero_points': array([], dtype=int32),\n",
       "  'quantized_dimension': 0},\n",
       " 'sparsity_parameters': {}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = interpreter.get_input_details()[0]\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f45883a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 28, 28), dtype=float32, numpy=\n",
       "array([[[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,  84., 185., 159., 151.,\n",
       "          60.,  36.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0., 222., 254., 254., 254.,\n",
       "         254., 241., 198., 198., 198., 198., 198., 198., 198., 198.,\n",
       "         170.,  52.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,  67., 114.,  72., 114.,\n",
       "         163., 227., 254., 225., 254., 254., 254., 250., 229., 254.,\n",
       "         254., 140.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,  17.,  66.,  14.,  67.,  67.,  67.,  59.,  21., 236.,\n",
       "         254., 106.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  83., 253.,\n",
       "         209.,  18.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,  22., 233., 255.,\n",
       "          83.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0., 129., 254., 238.,\n",
       "          44.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,  59., 249., 254.,  62.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0., 133., 254., 187.,   5.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   9., 205., 248.,  58.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0., 126., 254., 182.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,  75., 251., 240.,  57.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,  19., 221., 254., 166.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   3., 203., 254., 219.,  35.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,  38., 254., 254.,  77.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,  31., 224., 254., 115.,   1.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0., 133., 254., 254.,  52.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          61., 242., 254., 254.,  52.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         121., 254., 254., 219.,  40.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         121., 254., 207.,  18.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = tf.constant(x_test[0], shape=input['shape'], dtype=input['dtype'])\n",
    "input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f251313",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input['index'], input_data)\n",
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adf51e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'serving_default_flatten_input:0',\n",
       "  'index': 0,\n",
       "  'shape': array([ 1, 28, 28]),\n",
       "  'shape_signature': array([-1, 28, 28]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'arith.constant',\n",
       "  'index': 1,\n",
       "  'shape': array([2]),\n",
       "  'shape_signature': array([2]),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'tfl.quantize',\n",
       "  'index': 2,\n",
       "  'shape': array([ 1, 28, 28]),\n",
       "  'shape_signature': array([-1, 28, 28]),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (1.0, -128),\n",
       "  'quantization_parameters': {'scales': array([1.], dtype=float32),\n",
       "   'zero_points': array([-128]),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'tfl.pseudo_qconst',\n",
       "  'index': 3,\n",
       "  'shape': array([128]),\n",
       "  'shape_signature': array([128]),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.005678526125848293, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00567853], dtype=float32),\n",
       "   'zero_points': array([0]),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quant_dense_1/BiasAdd/ReadVariableOp',\n",
       "  'index': 4,\n",
       "  'shape': array([10]),\n",
       "  'shape_signature': array([10]),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.08103207498788834, 0),\n",
       "  'quantization_parameters': {'scales': array([0.08103207], dtype=float32),\n",
       "   'zero_points': array([0]),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quant_flatten/Reshape;sequential/quantize_layer/AllValuesQuantize/FakeQuantWithMinMaxVars',\n",
       "  'index': 5,\n",
       "  'shape': array([  1, 784]),\n",
       "  'shape_signature': array([ -1, 784]),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (1.0, -128),\n",
       "  'quantization_parameters': {'scales': array([1.], dtype=float32),\n",
       "   'zero_points': array([-128]),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quant_dense/MatMul;sequential/quant_dense/LastValueQuant/FakeQuantWithMinMaxVars',\n",
       "  'index': 6,\n",
       "  'shape': array([128, 784]),\n",
       "  'shape_signature': array([128, 784]),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.005678526125848293, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00567853], dtype=float32),\n",
       "   'zero_points': array([0]),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quant_dense/MatMul;sequential/quant_dense/Relu;sequential/quant_dense/BiasAdd',\n",
       "  'index': 7,\n",
       "  'shape': array([  1, 128]),\n",
       "  'shape_signature': array([ -1, 128]),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (14.565923690795898, -128),\n",
       "  'quantization_parameters': {'scales': array([14.565924], dtype=float32),\n",
       "   'zero_points': array([-128]),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quant_dense_1/MatMul;sequential/quant_dense_1/LastValueQuant/FakeQuantWithMinMaxVars',\n",
       "  'index': 8,\n",
       "  'shape': array([ 10, 128]),\n",
       "  'shape_signature': array([ 10, 128]),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.005563126411288977, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00556313], dtype=float32),\n",
       "   'zero_points': array([0]),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quant_dense_1/MatMul;sequential/quant_dense_1/BiasAdd',\n",
       "  'index': 9,\n",
       "  'shape': array([ 1, 10]),\n",
       "  'shape_signature': array([-1, 10]),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (64.0165023803711, -127),\n",
       "  'quantization_parameters': {'scales': array([64.0165], dtype=float32),\n",
       "   'zero_points': array([-127]),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'StatefulPartitionedCall:0',\n",
       "  'index': 10,\n",
       "  'shape': array([ 1, 10]),\n",
       "  'shape_signature': array([-1, 10]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_tensor_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efba3ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -90,  -88,  -75,  -75,  -98,  -78, -126,  -66,  -86,  -80]],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_tensor(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4a1bcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(interpreter.get_tensor(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b1fa1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-128, -128, -128, -128, -102, -128, -128, -103, -128, -113, -128,\n",
       "        -128, -128, -128, -128, -128, -128, -128, -128,  -84,  -95, -114,\n",
       "        -128, -110, -113, -128, -128, -128, -128, -128, -128,  -75,  -57,\n",
       "        -128, -128, -128, -128, -106, -128,  -88, -128, -103, -128, -120,\n",
       "        -128, -128, -128, -128, -128, -128, -128, -111,  -86, -128, -128,\n",
       "        -128, -128, -128, -128, -115,  -97, -122, -128, -128, -117, -128,\n",
       "         -97, -128, -128, -128, -128, -128,  -99, -128, -128, -128, -101,\n",
       "        -128, -128,  -24, -128, -113, -128, -128, -128, -128, -128, -128,\n",
       "        -128, -128, -128, -128, -128, -128, -128, -128, -128, -128, -128,\n",
       "        -118, -128, -128, -128, -128,  -65, -128, -128, -128, -128, -128,\n",
       "        -128, -128, -128, -128, -128, -128,  -94, -128, -128,  -95, -128,\n",
       "        -128, -128,  -86, -128,  -47, -128, -128]], dtype=int8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_tensor(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2fe518aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 55,  57,  20,  54,  51,  28,  37, -54,  16, -12, -23,  28,  37,\n",
       "         6,  50,   7, -49, -16,  -1,  44,  52,  52,  30,  54,   1,   7,\n",
       "       -15,  52,  34, -24,  52, -69,  50,  57, -51,  25,  65, -40, -36,\n",
       "        41,  33,  62,  -7, -76,  47,  44,  62,  21, -94, -64,  29, -37,\n",
       "        52,  57,  56, -10,  61,  49,  58,  52,  57,  48, -39,  30,  34,\n",
       "        46,  31,  48,  54,   8,  37, -45,  46,  50,  56,  62,  55,  -4,\n",
       "        38,  39,  36,  54, -82,  28,  67, -64,  45,  44,  -2,  42,  50,\n",
       "        17,  18,  39,  46, -21,  29,  50,  19,  45,  54, -60, -31,  -2,\n",
       "        30,  -5,  34,  11,  52,  48,  55,  56,  59,  51,  34,  11,  -1,\n",
       "       -16,  42,  41,  55,  61,  45,  43, -77,  45,  23,  73], dtype=int8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_tensor(8)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7ac5bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  2, -1,  3,  6,  1,  2,  4,  3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_tensor(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1e5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_4668\\2737353408.py:1: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  np.sum((x.astype(np.int32)*y.astype(np.int32) for x,y in zip(interpreter.get_tensor(7)[0], interpreter.get_tensor(8)[0]))).astype(np.int8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "np.sum((x.astype(np.int32)*y.astype(np.int32) for x,y in zip(interpreter.get_tensor(7)[0], interpreter.get_tensor(8)[0]))).astype(np.int8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
